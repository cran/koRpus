<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="m.eik michalke" />

<meta name="date" content="2026-02-02" />

<title>Using the koRpus Package for Text Analysis</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>
<meta name="flattr:id" content="4zdzgd" />

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>

<style type="text/css">
p.abstract{
text-align: center;
font-weight: bold;
}
div.abstract{
margin: auto;
width: 90%;
}
</style>


<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Using the koRpus Package for Text
Analysis</h1>
<h4 class="author">m.eik michalke</h4>
<h4 class="date">2026-02-02</h4>
<div class="abstract">
<p class="abstract">Abstract</p>
<p>The R package <code>koRpus</code> aims to be a versatile tool for
text analysis, with an emphasis on scientific research on that topic. It
implements dozens of formulae to measure readability and lexical
diversity. On a more basic level <code>koRpus</code> can be used as an R
wrapper for third party products, like the tokenizer and POS tagger
TreeTagger or language corpora of the Leipzig Corpora Collection. This
vignette takes a brief tour around its core components, shows how they
can be used and gives some insight on design decisions.</p>
</div>


<div id="TOC">
<ul>
<li><a href="#what-is-korpus" id="toc-what-is-korpus">What is
koRpus?</a></li>
<li><a href="#recommendations" id="toc-recommendations">Recommendations</a>
<ul>
<li><a href="#treetagger" id="toc-treetagger">TreeTagger</a></li>
<li><a href="#word-lists" id="toc-word-lists">Word lists</a></li>
<li><a href="#language-corpora" id="toc-language-corpora">Language
corpora</a></li>
<li><a href="#translated-human-rights-declaration" id="toc-translated-human-rights-declaration">Translated Human Rights
Declaration</a></li>
</ul></li>
<li><a href="#a-sample-session" id="toc-a-sample-session">A sample
session</a>
<ul>
<li><a href="#loading-a-language-package" id="toc-loading-a-language-package">Loading a language package</a></li>
<li><a href="#tokenizing-and-pos-tagging" id="toc-tokenizing-and-pos-tagging">Tokenizing and POS tagging</a>
<ul>
<li><a href="#treetag" id="toc-treetag"><code>treetag()</code></a></li>
<li><a href="#alternative-tokenize" id="toc-alternative-tokenize">Alternative:
<code>tokenize()</code></a></li>
<li><a href="#accessing-data-from-korpus-objects" id="toc-accessing-data-from-korpus-objects">Accessing data from
<code>koRpus</code> objects</a></li>
<li><a href="#descriptive-statistics" id="toc-descriptive-statistics">Descriptive statistics</a></li>
</ul></li>
<li><a href="#lexical-diversity-type-token-ratios" id="toc-lexical-diversity-type-token-ratios">Lexical diversity (type
token ratios)</a></li>
<li><a href="#frequency-analysis" id="toc-frequency-analysis">Frequency
analysis</a>
<ul>
<li><a href="#importing-language-corpora-data" id="toc-importing-language-corpora-data">Importing language corpora
data</a></li>
<li><a href="#conduct-a-frequency-analysis" id="toc-conduct-a-frequency-analysis">Conduct a frequency
analysis</a></li>
<li><a href="#new-to-the-desc-slot" id="toc-new-to-the-desc-slot">New to
the <code>desc</code> slot</a></li>
</ul></li>
<li><a href="#readability" id="toc-readability">Readability</a>
<ul>
<li><a href="#readability-from-numeric-data" id="toc-readability-from-numeric-data">Readability from numeric
data</a></li>
</ul></li>
<li><a href="#language-detection" id="toc-language-detection">Language
detection</a></li>
<li><a href="#using-korpus-with-other-pos-taggers" id="toc-using-korpus-with-other-pos-taggers">Using <code>koRpus</code>
with other POS taggers</a>
<ul>
<li><a href="#example-udpipe" id="toc-example-udpipe">Example:
<code>udpipe</code></a></li>
</ul></li>
</ul></li>
<li><a href="#extending-korpus" id="toc-extending-korpus">Extending
<code>koRpus</code></a></li>
<li><a href="#analyzing-full-corpora" id="toc-analyzing-full-corpora">Analyzing full corpora</a></li>
<li><a href="#acknowledgements" id="toc-acknowledgements">Acknowledgements</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<div id="what-is-korpus" class="section level1">
<h1>What is koRpus?</h1>
<p>Work on <code>koRpus</code> started in February 2011, primarily with
the goal in mind to examine how similar different texts are. Since then,
it quickly grew into an R package which implements dozens of formulae
for readability and lexical diversity, and wrappers for language corpus
databases and a tokenizer/POS tagger.</p>
</div>
<div id="recommendations" class="section level1">
<h1>Recommendations</h1>
<div id="treetagger" class="section level2">
<h2>TreeTagger</h2>
<p>At the very beginning of almost every analysis with this package, the
text you want to examine has to be sliced into its components, and the
components must be identified and named. That is, it has to be split
into its semantic parts (tokens), words, numbers, punctuation marks.
After that, each token will be tagged regarding its part-of-speech
(POS). For both of these steps, <code>koRpus</code> can use the third
party software <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/">TreeTagger</a>
<span class="citation">(Schmid, 1994)</span>.</p>
<p>Especially for Windows users installation of TreeTagger might be a
little more complex – e.g., it depends on Perl<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, and you need a tool
to extract .tar.gz archives.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Detailed installations instructions are
beyond the scope of this vignette.</p>
<p>If you don’t want to use TreeTagger, <code>koRpus</code> provides a
simple tokenizer of its own called <code>tokenize()</code>. While the
tokenizing itself works quite well, <code>tokenize()</code> is not as
elaborate as is TreeTagger when it comes to POS tagging, as it can
merely tell words from numbers, punctuation and abbreviations. Although
this is sufficient for most readability formulae, you can’t evaluate
word classes in detail. If that’s what you want, a TreeTagger
installation is needed.</p>
</div>
<div id="word-lists" class="section level2">
<h2>Word lists</h2>
<p>Some of the readability formulae depend on special word lists <span class="citation">(like Bormuth, 1968; Dale &amp; Chall, 1948; Spache,
1953)</span>. For copyright reasons these lists are not included as of
now. This means, as long as you don’t have copies of these lists, you
can’t calculate these particular measures, but of course all others. The
expected format to use a list with this package is a simple text file
with one word per line, preferably in UTF-8 encoding.</p>
</div>
<div id="language-corpora" class="section level2">
<h2>Language corpora</h2>
<p>The frequency analysis functions in this package can look up how
often each word in a text is used in its language, given that a corpus
database is provided. Databases in Celex format are support, as is the
Leipzig Corpora Collection <span class="citation">(Quasthoff, Richter,
&amp; Biemann, 2006)</span> file format. To use such a database with
this package, you simply need to download one of the .zip/.tar
files.</p>
</div>
<div id="translated-human-rights-declaration" class="section level2">
<h2>Translated Human Rights Declaration</h2>
<p>If you want to estimate the language of a text, reference texts in
known languages are needed. In <code>koRpus</code>, the <a href="https://www.unicode.org/udhr/">Universal Declaration of Human
Rights with its more than 350 translations</a> is used.</p>
</div>
</div>
<div id="a-sample-session" class="section level1">
<h1>A sample session</h1>
<p>From now on it is assumed that the above requirements are correctly
installed and working. If an optional component is used it will be
noted. Further, we’ll need a sample text to analyze. We’ll use the
section on <a href="https://en.wikipedia.org/wiki/Phasmatodea#Defense_mechanisms">defense
mechanisms of Phasmatodea</a> from Wikipedia for this purpose.</p>
<div id="loading-a-language-package" class="section level2">
<h2>Loading a language package</h2>
<p>In order to do some analysis, you need to load a language support
package for each language you would like to work with. For instance, in
this vignette we’re analyzing an English sample text. Language support
packages for <code>koRpus</code> are named <code>koRpus.lang.**</code>,
where <code>**</code> is a two-character ID for the respective language,
like <code>en</code> for English.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># install the language support package</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">install.koRpus.lang</span>(<span class="st">&quot;en&quot;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co"># load the package</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="fu">library</span>(koRpus.lang.en)</span></code></pre></div>
<p>When <code>koRpus</code> itself is loaded, it will list you all
language packages found on your system. To get a list of all installable
packages, call <code>available.koRpus.lang()</code>.</p>
</div>
<div id="tokenizing-and-pos-tagging" class="section level2">
<h2>Tokenizing and POS tagging</h2>
<p>As explained earlier, splitting the text up into its basic components
can be done by TreeTagger. To achieve this and have the results
available in R, the function <code>treetag()</code> is used.</p>
<div id="treetag" class="section level3">
<h3><code>treetag()</code></h3>
<p>At the very least you must provide it with the text, of course, and
name the language it is written in. In addition to that you must specify
where you installed TreeTagger. If you look at the package documentation
you’ll see that <code>treetag()</code> understands a number of options
to configure TreeTagger, but in most cases using one of the built-in
presets should suffice. TreeTagger comes with batch/shell scripts for
installed languages, and the presets of <code>treetag()</code> are
basically just R implementations of these scripts.</p>
<!--
  we can't evaluate this code if the package should go to CRAN
  because TreeTagger will not be present.
-->
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>tagged.text <span class="ot">&lt;-</span> <span class="fu">treetag</span>(</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>  <span class="st">&quot;sample_text.txt&quot;</span>,</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>  <span class="at">treetagger=</span><span class="st">&quot;manual&quot;</span>,</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>  <span class="at">lang=</span><span class="st">&quot;en&quot;</span>,</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>  <span class="at">TT.options=</span><span class="fu">list</span>(</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    <span class="at">path=</span><span class="st">&quot;~/bin/treetagger/&quot;</span>,</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>    <span class="at">preset=</span><span class="st">&quot;en&quot;</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>  ),</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>  <span class="at">doc_id=</span><span class="st">&quot;sample&quot;</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>)</span></code></pre></div>
<!--
  we work around that issue by silently loading the tagged text from a dput file
-->
<p>The first argument (file name) and <code>lang</code> should explain
themselves. The <code>treetagger</code> option can either take the full
path to one of the original TreeTagger scripts mentioned above, or the
keyword “manual”, which will cause the interpretation of what is defined
by <code>TT.options</code>. To use a preset, just put the
<code>path</code> to your local TreeTagger installation and a valid
<code>preset</code> name here.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> The document ID is optional and can be
omitted.</p>
<p>The resulting S4 object is of a class called <code>kRp.text</code>.
If you call the object directly you get a shortened view of it’s main
content:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>tagged.text</span></code></pre></div>
<pre><code>##     doc_id       token  tag     lemma lttr      wclass desc stop stem idx sntc
## 1   sample     Defense   NN   defense    7        noun &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   1    1
## 2   sample  mechanisms  NNS mechanism   10        noun &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   2    1
## 3   sample Phasmatodea   NP &lt;unknown&gt;   11        name &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   3    1
## 4   sample     species   NN   species    7        noun &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   4    1
## 5   sample     exhibit   NN   exhibit    7        noun &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   5    1
## 6   sample  mechanisms  NNS mechanism   10        noun &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   6    1
##                                                  [...]                        
## 612 sample  considered  VBN  consider   10        verb &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 612   18
## 613 sample    inedible   JJ  inedible    8   adjective &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 613   18
## 614 sample          by   IN        by    2 preposition &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 614   18
## 615 sample        some   DT      some    4  determiner &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 615   18
## 616 sample   predators  NNS  predator    9        noun &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 616   18
## 617 sample           . SENT         .    1    fullstop &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 617   18</code></pre>
<p>Once you’ve come this far, i.e., having a valid object of class
<code>kRp.text</code>, all following analyses should run smoothly.</p>
<div id="troubleshooting" class="section level4">
<h4>Troubleshooting</h4>
<p>If <code>treetag()</code> should fail, you should first re-run it
with the extra option <code>debug=TRUE</code>. Most interestingly, that
will print the contents of <code>sys.tt.call</code>, which is the
TreeTagger command given to your operating system for execution. With
that it should be possible to examine where exactly the erroneous
behavior starts.</p>
</div>
</div>
<div id="alternative-tokenize" class="section level3">
<h3>Alternative: <code>tokenize()</code></h3>
<p>If you don’t need detailed word class analysis, you should be fine
using <code>koRpus</code>’ own function <code>tokenize()</code>. As you
can see, <code>tokenize()</code> comes to the same results regarding the
tokens, but is rather limited in recognizing word classes:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>(tokenized.text <span class="ot">&lt;-</span> <span class="fu">tokenize</span>(</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    <span class="st">&quot;sample_text.txt&quot;</span>,</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    <span class="at">lang=</span><span class="st">&quot;en&quot;</span>,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    <span class="at">doc_id=</span><span class="st">&quot;sample&quot;</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>))</span></code></pre></div>
<pre><code>##     doc_id       token      tag lemma lttr   wclass desc stop stem idx sntc
## 1   sample     Defense word.kRp          7     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   1    1
## 2   sample  mechanisms word.kRp         10     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   2    1
## 3   sample Phasmatodea word.kRp         11     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   3    1
## 4   sample     species word.kRp          7     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   4    1
## 5   sample     exhibit word.kRp          7     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   5    1
## 6   sample  mechanisms word.kRp         10     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;   6    1
##                                               [...]                        
## 620 sample  considered word.kRp         10     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 620   20
## 621 sample    inedible word.kRp          8     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 621   20
## 622 sample          by word.kRp          2     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 622   20
## 623 sample        some word.kRp          4     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 623   20
## 624 sample   predators word.kRp          9     word &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 624   20
## 625 sample           .     .kRp          1 fullstop &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 625   20</code></pre>
</div>
<div id="accessing-data-from-korpus-objects" class="section level3">
<h3>Accessing data from <code>koRpus</code> objects</h3>
<p>For this class of objects, <code>koRpus</code> provides some
comfortable methods to extract the portions you’re interested in. For
example, the main results are to be found in the slot
<code>tokens</code>. In addition to TreeTagger’s original output (token,
tag and lemma) <code>treetag()</code> also automatically counts letters
and assigns tokens to global word classes. To get these results as a
data.frame, use the getter method <code>taggedText()</code>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">taggedText</span>(tagged.text)[<span class="dv">26</span><span class="sc">:</span><span class="dv">34</span>,]</span></code></pre></div>
<pre><code>##    doc_id     token tag    lemma lttr      wclass desc stop stem idx sntc
## 26 sample       and  CC      and    3 conjunction   NA   NA   NA  26    1
## 27 sample       are VBP       be    3        verb   NA   NA   NA  27    1
## 28 sample  deployed VBN   deploy    8        verb   NA   NA   NA  28    1
## 29 sample     after  IN    after    5 preposition   NA   NA   NA  29    1
## 30 sample        an  DT       an    2  determiner   NA   NA   NA  30    1
## 31 sample    attack  NN   attack    6        noun   NA   NA   NA  31    1
## 32 sample       has VBZ     have    3        verb   NA   NA   NA  32    1
## 33 sample      been VBN       be    4        verb   NA   NA   NA  33    1
## 34 sample initiated VBN initiate    9        verb   NA   NA   NA  34    1</code></pre>
<p>In case you want to access a subset of the data in the resulting
object, e.g., only the column with number of letters or the first five
rows of <code>tokens</code>, you’ll be happy to know there’s special
<code>[</code> and <code>[[</code> methods for these kinds of
objects:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">head</span>(tagged.text[[<span class="st">&quot;lttr&quot;</span>]], <span class="at">n=</span><span class="dv">50</span>)</span></code></pre></div>
<pre><code>##  [1]  7 10 11  7  7 10  3  7  4  9  4  4  7  2  6  4  9  2  3  5  5  1  7  7  1  3  3
## [28]  8  5  2  6  3  4  9  1  9  8  1  3  7  9  4  7 12  4 11  2 10  1  4</code></pre>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>tagged.text[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]</span></code></pre></div>
<pre><code>##   doc_id       token tag     lemma lttr wclass desc stop stem idx sntc
## 1 sample     Defense  NN   defense    7   noun   NA   NA   NA   1    1
## 2 sample  mechanisms NNS mechanism   10   noun   NA   NA   NA   2    1
## 3 sample Phasmatodea  NP &lt;unknown&gt;   11   name   NA   NA   NA   3    1
## 4 sample     species  NN   species    7   noun   NA   NA   NA   4    1
## 5 sample     exhibit  NN   exhibit    7   noun   NA   NA   NA   5    1</code></pre>
<p>The <code>[</code> and <code>[[</code> methods are basically a useful
shortcut replacements for <code>taggedText()</code>.</p>
</div>
<div id="descriptive-statistics" class="section level3">
<h3>Descriptive statistics</h3>
<p>All results of both <code>treetag()</code> and
<code>tokenize()</code> also provide various descriptive statistics
calculated from the analyzed text. You can get them by calling
<code>describe()</code> on the object:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">describe</span>(tagged.text)</span></code></pre></div>
<pre><code>## $all.chars
## [1] 3554
## 
## $lines
## [1] 10
## 
## $normalized.space
## [1] 3549
## 
## $chars.no.space
## [1] 2996
## 
## $punct
## [1] 78
## 
## $digits
## [1] 4
## 
## $letters
##  all   l1   l2   l3   l4   l5   l6   l7   l8   l9  l10  l11  l12  l13  l14  l15  l16 
## 2918   19   92   74   80   51   49   65   43   35   22   15    6    3    0    1    1 
## 
## $letters.only
## [1] 2914
## 
## $char.distrib
##                 1         2         3         4          5          6         7
## num      80.00000  92.00000  74.00000  80.00000  51.000000  49.000000  65.00000
## cum.sum  80.00000 172.00000 246.00000 326.00000 377.000000 426.000000 491.00000
## cum.inv 537.00000 445.00000 371.00000 291.00000 240.000000 191.000000 126.00000
## pct      12.96596  14.91086  11.99352  12.96596   8.265802   7.941653  10.53485
## cum.pct  12.96596  27.87682  39.87034  52.83630  61.102107  69.043760  79.57861
## pct.inv  87.03404  72.12318  60.12966  47.16370  38.897893  30.956240  20.42139
##                  8          9         10         11          12          13
## num      43.000000  35.000000  22.000000  15.000000   6.0000000   3.0000000
## cum.sum 534.000000 569.000000 591.000000 606.000000 612.0000000 615.0000000
## cum.inv  83.000000  48.000000  26.000000  11.000000   5.0000000   2.0000000
## pct       6.969206   5.672609   3.565640   2.431118   0.9724473   0.4862237
## cum.pct  86.547812  92.220421  95.786062  98.217180  99.1896272  99.6758509
## pct.inv  13.452188   7.779579   4.213938   1.782820   0.8103728   0.3241491
##                  14          15          16
## num       0.0000000   1.0000000   1.0000000
## cum.sum 615.0000000 616.0000000 617.0000000
## cum.inv   2.0000000   1.0000000   0.0000000
## pct       0.0000000   0.1620746   0.1620746
## cum.pct  99.6758509  99.8379254 100.0000000
## pct.inv   0.3241491   0.1620746   0.0000000
## 
## $lttr.distrib
##                  1         2         3         4          5         6         7
## num      19.000000  92.00000  74.00000  80.00000  51.000000  49.00000  65.00000
## cum.sum  19.000000 111.00000 185.00000 265.00000 316.000000 365.00000 430.00000
## cum.inv 537.000000 445.00000 371.00000 291.00000 240.000000 191.00000 126.00000
## pct       3.417266  16.54676  13.30935  14.38849   9.172662   8.81295  11.69065
## cum.pct   3.417266  19.96403  33.27338  47.66187  56.834532  65.64748  77.33813
## pct.inv  96.582734  80.03597  66.72662  52.33813  43.165468  34.35252  22.66187
##                  8          9         10         11          12          13
## num      43.000000  35.000000  22.000000  15.000000   6.0000000   3.0000000
## cum.sum 473.000000 508.000000 530.000000 545.000000 551.0000000 554.0000000
## cum.inv  83.000000  48.000000  26.000000  11.000000   5.0000000   2.0000000
## pct       7.733813   6.294964   3.956835   2.697842   1.0791367   0.5395683
## cum.pct  85.071942  91.366906  95.323741  98.021583  99.1007194  99.6402878
## pct.inv  14.928058   8.633094   4.676259   1.978417   0.8992806   0.3597122
##                  14          15          16
## num       0.0000000   1.0000000   1.0000000
## cum.sum 554.0000000 555.0000000 556.0000000
## cum.inv   2.0000000   1.0000000   0.0000000
## pct       0.0000000   0.1798561   0.1798561
## cum.pct  99.6402878  99.8201439 100.0000000
## pct.inv   0.3597122   0.1798561   0.0000000
## 
## $words
## [1] 556
## 
## $sentences
## [1] 18
## 
## $avg.sentc.length
## [1] 30.88889
## 
## $avg.word.length
## [1] 5.248201
## 
## $doc_id
## [1] &quot;sample&quot;</code></pre>
<p>Amongst others, you will find several indices describing the number
of characters:</p>
<ul>
<li><code>all.chars</code>: Counts each character, including all space
characters</li>
<li><code>normalized.space</code>: Like <code>all.chars</code>, but
clusters of space characters (incl. line breaks) are counted only as one
character</li>
<li><code>chars.no.space</code>: Counts all characters except any space
characters</li>
<li><code>letters.only</code>: Counts only letters, excluding(!) digits
(which are counted seperately as <code>digits</code>)</li>
</ul>
<p>You’ll also find the number of <code>words</code> and
<code>sentences</code>, as well as average word and sentence lengths,
and tables describing how the word length is distributed throughout the
text (<code>lttr.distrib</code>). For instance, we see that the text has
74 words with three letters, 185 with three or less, and 371 with more
than three. The last three lines show the percentages, respectively.</p>
</div>
</div>
<div id="lexical-diversity-type-token-ratios" class="section level2">
<h2>Lexical diversity (type token ratios)</h2>
<p>To analyze the lexical diversity of our text we can now simply hand
over the tagged text object to the <code>lex.div()</code> method. You
can call it on the object with no further arguments (like
<code>lex.div(tagged.text)</code>), but in this example we’ll limit the
analysis to a few measures:<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="fu">lex.div</span>(</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>  tagged.text,</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>  <span class="at">measure=</span><span class="fu">c</span>(<span class="st">&quot;TTR&quot;</span>, <span class="st">&quot;MSTTR&quot;</span>, <span class="st">&quot;MATTR&quot;</span>,<span class="st">&quot;HD-D&quot;</span>, <span class="st">&quot;MTLD&quot;</span>, <span class="st">&quot;MTLD-MA&quot;</span>),</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>  <span class="at">char=</span><span class="fu">c</span>(<span class="st">&quot;TTR&quot;</span>, <span class="st">&quot;MATTR&quot;</span>,<span class="st">&quot;HD-D&quot;</span>, <span class="st">&quot;MTLD&quot;</span>, <span class="st">&quot;MTLD-MA&quot;</span>)</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>)</span></code></pre></div>
<!-- the status bars ruin the document, silencing them for the actual output -->
<pre><code>## 
## Total number of tokens: 556 
## Total number of types:  294
## Total number of lemmas: 283
## 
## Type-Token Ratio
##                TTR: 0.53 
## 
## TTR characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.5297  0.5466  0.5930  0.6188  0.6491  1.0000 
##    SD
##  0.0907
## 
## 
## Mean Segmental Type-Token Ratio
##              MSTTR: 0.72 
##         SD of TTRs: 0.03 
##       Segment size: 100 
##     Tokens dropped: 56 
## 
## Hint: A segment size of 92 would reduce the drop rate to 4.
##       Maybe try ?segment.optimizer()
## 
## 
## Moving-Average Type-Token Ratio
##              MATTR: 0.74 
##         SD of TTRs: 0.03 
##        Window size: 100 
## 
## MATTR characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.7138  0.7239  0.7308  0.7290  0.7341  0.7368 
##    SD
##  0.0066
## 
## 
## HD-D
##               HD-D: 35.54 
##               ATTR: 0.85 
##        Sample size: 42 
## 
## HD-D characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    5.00   35.46   35.62   34.31   35.82   36.16 
##    SD
##  5.0648
## 
## 
## Measure of Textual Lexical Diversity
##               MTLD: 97.5 
##  Number of factors: NA 
##        Factor size: 0.72 
##   SD tokens/factor: 36.08 (all factors) 
##                     26.06 (complete factors only)
## 
## MTLD characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   14.00   79.07   88.37   83.21   92.92  104.40       1 
##    SD
##  15.9015
## 
## 
## Moving-Average Measure of Textual Lexical Diversity
##            MTLD-MA: 102.73 
##   SD tokens/factor: 26.74 
##          Step size: 1 
##        Factor size: 0.72 
##        Min. tokens: 9 
## 
## MTLD-MA characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   63.00   92.99   96.57   95.89  102.76  107.99      12 
##    SD
##  9.6766</code></pre>
<pre><code>## 
## Note: Analysis was conducted case insensitive.</code></pre>
<p>Let’s look at some particular parts: At first we are informed of the
total number of types, tokens and lemmas (if available). After that the
actual results are being printed, using the package’s
<code>show()</code> method for this particular kind of object. As you
can see, it prints the actual value of each measure before a summary of
the characteristics.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>Some measures return more information than just their actual index
value. For instance, when the Mean Segmental Type-Token Ratio is
calculated, you’ll be informed how much of your text was dropped and
hence not examined. A small feature tool of <code>koRpus</code>,
<code>segment.optimizer()</code>, automatically recommends you with a
different segment size if this could decrease the number of lost
tokens.</p>
<p>By default, <code>lex.div()</code> calculates every measure of
lexical diversity that was implemented. Of course this is fully
configurable, e.g. to completely skip the calculation of characteristics
just add the option <code>char=NULL</code>. If you’re only interested in
one particular measure, it might be more convenient to call the
according wrapper function instead of <code>lex.div()</code>. For
example, to calculate only the measures proposed by <span class="citation">Maas (1972)</span>:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="fu">maas</span>(tagged.text)</span></code></pre></div>
<pre><code>## Language: &quot;en&quot;</code></pre>
<pre><code>## TTR.char: Calculate TTR values</code></pre>
<pre><code>##   |                                                                                   |                                                                           |   0%  |                                                                                   |=                                                                          |   1%  |                                                                                   |=                                                                          |   2%  |                                                                                   |==                                                                         |   3%  |                                                                                   |===                                                                        |   4%  |                                                                                   |===                                                                        |   5%  |                                                                                   |====                                                                       |   5%  |                                                                                   |=====                                                                      |   6%  |                                                                                   |=====                                                                      |   7%  |                                                                                   |======                                                                     |   8%  |                                                                                   |=======                                                                    |   9%  |                                                                                   |=======                                                                    |  10%  |                                                                                   |========                                                                   |  11%  |                                                                                   |=========                                                                  |  12%  |                                                                                   |=========                                                                  |  13%  |                                                                                   |==========                                                                 |  14%  |                                                                                   |===========                                                                |  14%  |                                                                                   |===========                                                                |  15%  |                                                                                   |============                                                               |  16%  |                                                                                   |=============                                                              |  17%  |                                                                                   |==============                                                             |  18%  |                                                                                   |==============                                                             |  19%  |                                                                                   |===============                                                            |  20%  |                                                                                   |================                                                           |  21%  |                                                                                   |================                                                           |  22%  |                                                                                   |=================                                                          |  23%  |                                                                                   |==================                                                         |  23%  |                                                                                   |==================                                                         |  24%  |                                                                                   |===================                                                        |  25%  |                                                                                   |====================                                                       |  26%  |                                                                                   |====================                                                       |  27%  |                                                                                   |=====================                                                      |  28%  |                                                                                   |======================                                                     |  29%  |                                                                                   |======================                                                     |  30%  |                                                                                   |=======================                                                    |  31%  |                                                                                   |========================                                                   |  32%  |                                                                                   |=========================                                                  |  33%  |                                                                                   |==========================                                                 |  34%  |                                                                                   |==========================                                                 |  35%  |                                                                                   |===========================                                                |  36%  |                                                                                   |============================                                               |  37%  |                                                                                   |============================                                               |  38%  |                                                                                   |=============================                                              |  39%  |                                                                                   |==============================                                             |  40%  |                                                                                   |==============================                                             |  41%  |                                                                                   |===============================                                            |  41%  |                                                                                   |================================                                           |  42%  |                                                                                   |================================                                           |  43%  |                                                                                   |=================================                                          |  44%  |                                                                                   |==================================                                         |  45%  |                                                                                   |==================================                                         |  46%  |                                                                                   |===================================                                        |  47%  |                                                                                   |====================================                                       |  48%  |                                                                                   |====================================                                       |  49%  |                                                                                   |=====================================                                      |  50%  |                                                                                   |======================================                                     |  50%  |                                                                                   |=======================================                                    |  51%  |                                                                                   |=======================================                                    |  52%  |                                                                                   |========================================                                   |  53%  |                                                                                   |=========================================                                  |  54%  |                                                                                   |=========================================                                  |  55%  |                                                                                   |==========================================                                 |  56%  |                                                                                   |===========================================                                |  57%  |                                                                                   |===========================================                                |  58%  |                                                                                   |============================================                               |  59%  |                                                                                   |=============================================                              |  59%  |                                                                                   |=============================================                              |  60%  |                                                                                   |==============================================                             |  61%  |                                                                                   |===============================================                            |  62%  |                                                                                   |===============================================                            |  63%  |                                                                                   |================================================                           |  64%  |                                                                                   |=================================================                          |  65%  |                                                                                   |=================================================                          |  66%  |                                                                                   |==================================================                         |  67%  |                                                                                   |===================================================                        |  68%  |                                                                                   |====================================================                       |  69%  |                                                                                   |=====================================================                      |  70%  |                                                                                   |=====================================================                      |  71%  |                                                                                   |======================================================                     |  72%  |                                                                                   |=======================================================                    |  73%  |                                                                                   |=======================================================                    |  74%  |                                                                                   |========================================================                   |  75%  |                                                                                   |=========================================================                  |  76%  |                                                                                   |=========================================================                  |  77%  |                                                                                   |==========================================================                 |  77%  |                                                                                   |===========================================================                |  78%  |                                                                                   |===========================================================                |  79%  |                                                                                   |============================================================               |  80%  |                                                                                   |=============================================================              |  81%  |                                                                                   |=============================================================              |  82%  |                                                                                   |==============================================================             |  83%  |                                                                                   |===============================================================            |  84%  |                                                                                   |================================================================           |  85%  |                                                                                   |================================================================           |  86%  |                                                                                   |=================================================================          |  86%  |                                                                                   |==================================================================         |  87%  |                                                                                   |==================================================================         |  88%  |                                                                                   |===================================================================        |  89%  |                                                                                   |====================================================================       |  90%  |                                                                                   |====================================================================       |  91%  |                                                                                   |=====================================================================      |  92%  |                                                                                   |======================================================================     |  93%  |                                                                                   |======================================================================     |  94%  |                                                                                   |=======================================================================    |  95%  |                                                                                   |========================================================================   |  95%  |                                                                                   |========================================================================   |  96%  |                                                                                   |=========================================================================  |  97%  |                                                                                   |========================================================================== |  98%  |                                                                                   |========================================================================== |  99%  |                                                                                   |===========================================================================| 100%</code></pre>
<pre><code>## 
## Total number of tokens: 556 
## Total number of types:  294
## Total number of lemmas: 283
## TTR characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.5297  0.5466  0.5930  0.6188  0.6491  1.0000 
##    SD
##  0.0907
## 
## 
## Maas&#39; Indices
##                  a: 0.19 
##               lgV0: 5.64 
##              lgeV0: 12.99 
## 
## Relative vocabulary growth (first half to full text)
##                  a: 0.81 
##               lgV0: 6.75 
##                 V&#39;: 0.43 (43 new types every 100 tokens)</code></pre>
<pre><code>## 
## Note: Analysis was conducted case insensitive.</code></pre>
<p>All wrapper functions have characteristics turned off by default. The
following example demonstrates how to calculate and plot the classic
type-token ratio with characteristics. The resulting plot shows the
typical degredation of TTR values with increasing text length:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>ttr.res <span class="ot">&lt;-</span> <span class="fu">TTR</span>(tagged.text, <span class="at">char=</span><span class="cn">TRUE</span>)</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="fu">plot</span>(ttr.res<span class="sc">@</span>TTR.char, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">main=</span><span class="st">&quot;TTR degredation over text length&quot;</span>)</span></code></pre></div>
<!-- same here silencing the status bars -->
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>Since this package is intended for research, it is possible to
directly influence all relevant values of each measure and examine the
effects. For example, as mentioned before
<code>segment.optimizer()</code> recommended a change of segment size
for MSTTR to drop less words, which is easily done:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="fu">MSTTR</span>(tagged.text, <span class="at">segment=</span><span class="dv">92</span>)</span></code></pre></div>
<pre><code>## Language: &quot;en&quot;</code></pre>
<pre><code>## TTR.char: Calculate TTR values</code></pre>
<pre><code>##   |                                                                                   |                                                                           |   0%  |                                                                                   |=                                                                          |   1%  |                                                                                   |=                                                                          |   2%  |                                                                                   |==                                                                         |   3%  |                                                                                   |===                                                                        |   4%  |                                                                                   |===                                                                        |   5%  |                                                                                   |====                                                                       |   5%  |                                                                                   |=====                                                                      |   6%  |                                                                                   |=====                                                                      |   7%  |                                                                                   |======                                                                     |   8%  |                                                                                   |=======                                                                    |   9%  |                                                                                   |=======                                                                    |  10%  |                                                                                   |========                                                                   |  11%  |                                                                                   |=========                                                                  |  12%  |                                                                                   |=========                                                                  |  13%  |                                                                                   |==========                                                                 |  14%  |                                                                                   |===========                                                                |  14%  |                                                                                   |===========                                                                |  15%  |                                                                                   |============                                                               |  16%  |                                                                                   |=============                                                              |  17%  |                                                                                   |==============                                                             |  18%  |                                                                                   |==============                                                             |  19%  |                                                                                   |===============                                                            |  20%  |                                                                                   |================                                                           |  21%  |                                                                                   |================                                                           |  22%  |                                                                                   |=================                                                          |  23%  |                                                                                   |==================                                                         |  23%  |                                                                                   |==================                                                         |  24%  |                                                                                   |===================                                                        |  25%  |                                                                                   |====================                                                       |  26%  |                                                                                   |====================                                                       |  27%  |                                                                                   |=====================                                                      |  28%  |                                                                                   |======================                                                     |  29%  |                                                                                   |======================                                                     |  30%  |                                                                                   |=======================                                                    |  31%  |                                                                                   |========================                                                   |  32%  |                                                                                   |=========================                                                  |  33%  |                                                                                   |==========================                                                 |  34%  |                                                                                   |==========================                                                 |  35%  |                                                                                   |===========================                                                |  36%  |                                                                                   |============================                                               |  37%  |                                                                                   |============================                                               |  38%  |                                                                                   |=============================                                              |  39%  |                                                                                   |==============================                                             |  40%  |                                                                                   |==============================                                             |  41%  |                                                                                   |===============================                                            |  41%  |                                                                                   |================================                                           |  42%  |                                                                                   |================================                                           |  43%  |                                                                                   |=================================                                          |  44%  |                                                                                   |==================================                                         |  45%  |                                                                                   |==================================                                         |  46%  |                                                                                   |===================================                                        |  47%  |                                                                                   |====================================                                       |  48%  |                                                                                   |====================================                                       |  49%  |                                                                                   |=====================================                                      |  50%  |                                                                                   |======================================                                     |  50%  |                                                                                   |=======================================                                    |  51%  |                                                                                   |=======================================                                    |  52%  |                                                                                   |========================================                                   |  53%  |                                                                                   |=========================================                                  |  54%  |                                                                                   |=========================================                                  |  55%  |                                                                                   |==========================================                                 |  56%  |                                                                                   |===========================================                                |  57%  |                                                                                   |===========================================                                |  58%  |                                                                                   |============================================                               |  59%  |                                                                                   |=============================================                              |  59%  |                                                                                   |=============================================                              |  60%  |                                                                                   |==============================================                             |  61%  |                                                                                   |===============================================                            |  62%  |                                                                                   |===============================================                            |  63%  |                                                                                   |================================================                           |  64%  |                                                                                   |=================================================                          |  65%  |                                                                                   |=================================================                          |  66%  |                                                                                   |==================================================                         |  67%  |                                                                                   |===================================================                        |  68%  |                                                                                   |====================================================                       |  69%  |                                                                                   |=====================================================                      |  70%  |                                                                                   |=====================================================                      |  71%  |                                                                                   |======================================================                     |  72%  |                                                                                   |=======================================================                    |  73%  |                                                                                   |=======================================================                    |  74%  |                                                                                   |========================================================                   |  75%  |                                                                                   |=========================================================                  |  76%  |                                                                                   |=========================================================                  |  77%  |                                                                                   |==========================================================                 |  77%  |                                                                                   |===========================================================                |  78%  |                                                                                   |===========================================================                |  79%  |                                                                                   |============================================================               |  80%  |                                                                                   |=============================================================              |  81%  |                                                                                   |=============================================================              |  82%  |                                                                                   |==============================================================             |  83%  |                                                                                   |===============================================================            |  84%  |                                                                                   |================================================================           |  85%  |                                                                                   |================================================================           |  86%  |                                                                                   |=================================================================          |  86%  |                                                                                   |==================================================================         |  87%  |                                                                                   |==================================================================         |  88%  |                                                                                   |===================================================================        |  89%  |                                                                                   |====================================================================       |  90%  |                                                                                   |====================================================================       |  91%  |                                                                                   |=====================================================================      |  92%  |                                                                                   |======================================================================     |  93%  |                                                                                   |======================================================================     |  94%  |                                                                                   |=======================================================================    |  95%  |                                                                                   |========================================================================   |  95%  |                                                                                   |========================================================================   |  96%  |                                                                                   |=========================================================================  |  97%  |                                                                                   |========================================================================== |  98%  |                                                                                   |========================================================================== |  99%  |                                                                                   |===========================================================================| 100%</code></pre>
<pre><code>## 
## Total number of tokens: 556 
## Total number of types:  294
## Total number of lemmas: 283
## TTR characteristics:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.5297  0.5466  0.5930  0.6188  0.6491  1.0000 
##    SD
##  0.0907
## 
## 
## Mean Segmental Type-Token Ratio
##              MSTTR: 0.75 
##         SD of TTRs: 0.04 
##       Segment size: 92 
##     Tokens dropped: 4</code></pre>
<pre><code>## 
## Note: Analysis was conducted case insensitive.</code></pre>
<p>Please see to the documentation for more detailed information on the
available measures and their references.</p>
</div>
<div id="frequency-analysis" class="section level2">
<h2>Frequency analysis</h2>
<div id="importing-language-corpora-data" class="section level3">
<h3>Importing language corpora data</h3>
<p>This package has rudimentary support to import corpus databases.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> That is,
it can read frequency data for words into an R object and use this
object for further analysis. Next to the <a href="http://celex.mpi.nl">Celex</a> database format
(<code>read.corp.celex()</code>), it can read the LCC flatfile format<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>
(<code>read.corp.LCC()</code>). The latter might be of special interest,
because the needed database archives can be <a href="https://wortschatz.uni-leipzig.de/en/download/">freely
downloaded</a>. Once you’ve downloaded one of these archives, it can be
comfortably imported:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>LCC.en <span class="ot">&lt;-</span> <span class="fu">read.corp.LCC</span>(<span class="st">&quot;~/downloads/corpora/eng_news_2010_1M-text.tar&quot;</span>)</span></code></pre></div>
<p><code>read.corp.LCC()</code> will automatically extract the files it
needs from the archive. Alernatively, you can specify the path to the
unpacked archive as well. To work with the imported data directly, the
tool <code>query()</code> was added to the package. It helps you to
comfortably look up certain words, or ranges of interesting values:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="fu">query</span>(LCC.en, <span class="st">&quot;word&quot;</span>, <span class="st">&quot;what&quot;</span>)</span></code></pre></div>
<!-- we need to fake these results, as there will not be a corpus database around -->
<pre><code>##     num word  freq         pct pmio    log10 rank.avg rank.min rank.rel.avg
## 160 210 what 16396 0.000780145  780 2.892095   260759   260759     99.95362
##     rank.rel.min
## 160     99.95362</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="fu">query</span>(LCC.en, <span class="st">&quot;pmio&quot;</span>, <span class="fu">c</span>(<span class="dv">780</span>, <span class="dv">790</span>))</span></code></pre></div>
<pre><code>##     num  word  freq          pct pmio    log10 rank.avg rank.min rank.rel.avg
## 156 206  many 16588 0.0007892806  789 2.897077   260763   260763     99.95515
## 157 207   per 16492 0.0007847128  784 2.894316   260762   260762     99.95477
## 158 208  down 16468 0.0007835708  783 2.893762   260761   260761     99.95439
## 159 209 since 16431 0.0007818103  781 2.892651   260760   260760     99.95400
## 160 210  what 16396 0.0007801450  780 2.892095   260759   260759     99.95362
##     rank.rel.min
## 156     99.95515
## 157     99.95477
## 158     99.95439
## 159     99.95400
## 160     99.95362</code></pre>
</div>
<div id="conduct-a-frequency-analysis" class="section level3">
<h3>Conduct a frequency analysis</h3>
<p>We can now conduct a full frequency analysis of our text:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a>freq.analysis.res <span class="ot">&lt;-</span> <span class="fu">freq.analysis</span>(tagged.text, <span class="at">corp.freq=</span>LCC.en)</span></code></pre></div>
<p>The resulting object holds a lot of information, even if no corpus
data was used (i.e., <code>corp.freq=NULL</code>). To begin with, it
contains the two slots <code>tokens</code> and <code>lang</code>, which
are copied from the analyzed tagged text object. In this way analysis
results can always be converted back into <code>kRp.text</code>
objects.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>
However, if corpus data was provided, the tagging results gained three
new columns:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a><span class="fu">taggedText</span>(freq.analysis.res)</span></code></pre></div>
<pre><code>##        token tag     lemma lttr  [...] pmio rank.avg rank.min
[...]
## 30        an  DT        an    2        3817 99.98735 99.98735
## 31    attack  NN    attack    6         163 99.70370 99.70370
## 32       has VBZ      have    3        4318 99.98888 99.98888
## 33      been VBN        be    4        2488 99.98313 99.98313
## 34 initiated VBN  initiate    9          11 97.32617 97.32137
## 35         (   (         (    1         854 99.96013 99.96013
## 36 secondary  JJ secondary    9          21 98.23846 98.23674
## 37   defense  NN   defense    7         210 99.77499 99.77499
## 38         )   )         )    1         856 99.96052 99.96052
[...]</code></pre>
<p>Perhaps most informatively, <code>pmio</code> shows how often the
respective token appears in a million tokens, according to the corpus
data. Adding to this, the previously introduced slot <code>desc</code>
now contains some more descriptive statistics on our text, and if we
provided a corpus database, the slot <code>freq.analysis</code> lists
summaries of various frequency information that was calculated.</p>
<p>If the corpus object also provided inverse document frequency (i.e.,
values in column <code>idf</code>) data, <code>freq.analysis()</code>
will automatically compute tf-idf statistics and put them in a column
called <code>tfidf</code>.</p>
</div>
<div id="new-to-the-desc-slot" class="section level3">
<h3>New to the <code>desc</code> slot</h3>
<p>Amongst others, the descriptives now also give easy access to
character vectors with all words (<code>$all.words</code>) and all
lemmata (<code>$all.lemmata</code>), all tokens sorted<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> into word classes
(e.g., all verbs in <code>$classes$verb</code>), or the number of words
in each sentece:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a><span class="fu">describe</span>(freq.analysis.res)[[<span class="st">&quot;sentc.length&quot;</span>]]</span></code></pre></div>
<pre><code>##  [1] 34 10 37 16 44 31 14 31 34 23 17 43 40 47 22 19 65 29</code></pre>
<p>As a practical example, the list <code>$classes</code> has proven to
be very helpful to debug the results of TreeTagger, which is remarkably
accurate, but of course not free from making a mistake now and then. By
looking through <code>$classes</code>, where all tokens are grouped
regarding to the global word class TreeTagger attributed to it, at least
obvious errors (like names mistakenly taken for a pronoun) are easily
found:<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a><span class="fu">describe</span>(freq.analysis.res)<span class="sc">$</span>classes</span></code></pre></div>
<pre><code>## $conjunction
## [1] &quot;both&quot; &quot;and&quot;  &quot;and&quot;  &quot;and&quot;  &quot;and&quot;  &quot;or&quot;   &quot;or&quot;   &quot;and&quot;  &quot;and&quot;  &quot;or&quot;  
## [11] &quot;and&quot;  &quot;or&quot;   &quot;and&quot;  &quot;or&quot;   &quot;and&quot;  &quot;and&quot;  &quot;and&quot;  &quot;and&quot; 
## 
## $number
## [1] &quot;20&quot;  &quot;one&quot;
## 
## $determiner
##  [1] &quot;an&quot;      &quot;the&quot;     &quot;an&quot;      &quot;The&quot;     &quot;the&quot;     &quot;the&quot;     &quot;some&quot;   
##  [8] &quot;that&quot;    &quot;Some&quot;    &quot;the&quot;     &quot;a&quot;       &quot;a&quot;       &quot;a&quot;       &quot;the&quot;    
## [15] &quot;that&quot;    &quot;the&quot;     &quot;the&quot;     &quot;Another&quot; &quot;which&quot;   &quot;the&quot;     &quot;a&quot;      
## [22] &quot;that&quot;    &quot;a&quot;       &quot;The&quot;     &quot;a&quot;       &quot;the&quot;     &quot;that&quot;    &quot;a&quot;      
[...]</code></pre>
</div>
</div>
<div id="readability" class="section level2">
<h2>Readability</h2>
<p>The package comes with implementations of several readability
formulae. Some of them depend on the number of syllables in the text.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> To
achieve this, the method <code>hyphen()</code> takes objects of class
<code>kRp.text</code> and applies an hyphenation algorithm <span class="citation">(Liang, 1983)</span> to each word. This algorithm was
originally developed for automatic word hyphenation in <span class="math inline">\(\LaTeX\)</span>, and is gracefully misused here to
fulfill a slightly different service.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a>(hyph.txt.en <span class="ot">&lt;-</span> <span class="fu">hyphen</span>(tagged.text))</span></code></pre></div>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" tabindex="-1"></a>hyph.txt.en</span></code></pre></div>
<pre><code>##     syll           word
## 1      2       De-fense
## 2      3   mech-a-nisms
## 3      4 Phasm-a-to-dea
## 4      2       spe-cies
## 5      3      ex-hib-it
## 6      3   mech-a-nisms
##       NA      [...]    
## 551    1             is
## 552    3   con-sid-ered
## 553    4    in-ed-i-ble
## 554    1             by
## 555    1           some
## 556    3    pred-a-tors</code></pre>
<p>This seperate hyphenation step can actually be skipped, as
<code>readability()</code> will do it automatically if needed. But
similar to TreeTagger, <code>hyphen()</code> will most likely not
produce perfect results. As a rule of thumb, if in doubt it seems to
behave rather conservative, that is, is underestimates the real number
of syllables in a text. This, however, would of course affect the
results of several readability formulae.</p>
<p>So, the more accurate the end results should be, the less you should
rely on the automatic hyphenation alone. But it sure is a good starting
point, for there is a method called <code>correct.hyph()</code> to help
you clean these results of errors later on. The most straight forward
way to do this is to call <code>hyphenText(hyph.txt.en)</code>, which
will get you a data frame with two colums, <code>word</code> (the
hyphenated words) and <code>syll</code> (the number of syllables), in a
spread sheet editor:<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">hyphenText</span>(hyph.txt.en))</span></code></pre></div>
<pre><code>##   syll           word
## 1    2       De-fense
## 2    3   mech-a-nisms
## 3    4 Phasm-a-to-dea
## 4    2       spe-cies
## 5    3      ex-hib-it
## 6    3   mech-a-nisms</code></pre>
<p>You can then manually correct wrong hyphenations by removing or
inserting “-” as hyphenation indicators, and call
<code>correct.hyph()</code> without further arguments, which will cause
it to recount all syllables:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" tabindex="-1"></a>hyph.txt.en <span class="ot">&lt;-</span> <span class="fu">correct.hyph</span>(hyph.txt.en)</span></code></pre></div>
<p>But the method can also be used to alter entries directly, which
might be simpler and cleaner than manual changes:</p>
<!-- this can cause errors if updated hyphen patterns lead to slighty different results in the first place -->
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" tabindex="-1"></a>hyph.txt.en <span class="ot">&lt;-</span> <span class="fu">correct.hyph</span>(hyph.txt.en, <span class="at">word=</span><span class="st">&quot;mech-a-nisms&quot;</span>, <span class="at">hyphen=</span><span class="st">&quot;mech-a-ni-sms&quot;</span>)</span></code></pre></div>
<pre><code>## Changed
## 
##   syll         word
## 2    3 mech-a-nisms
## 6    3 mech-a-nisms
## 
##   into
## 
##   syll          word
## 2    4 mech-a-ni-sms
## 6    4 mech-a-ni-sms</code></pre>
<p>The hyphenated text object can now be given to
<code>readability()</code>, to calculate the measures of interest:<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a>readbl.txt <span class="ot">&lt;-</span> <span class="fu">readability</span>(tagged.text, <span class="at">hyphen=</span>hyph.txt.en)</span></code></pre></div>
<p>Similar to <code>lex.div()</code>, by default
<code>readability()</code> calculates almost<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a> all available
measures:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" tabindex="-1"></a>readbl.txt</span></code></pre></div>
<pre><code>## 
## Automated Readability Index (ARI)
##   Parameters: default 
##        Grade: 18.73 
## 
## 
## Coleman Formulas
##   Parameters: default 
##     Pronouns: 1.62 (per 100 words)
##      Prepos.: 13.49 (per 100 words)
##    Formula 1: 39% cloze completions
##    Formula 2: 37% cloze completions
##    Formula 3: 35% cloze completions
##    Formula 4: 36% cloze completions
## 
## 
## Coleman-Liau
##   Parameters: default 
##          ECP: 33% (estimted cloze percentage)
##        Grade: 14.1 
##        Grade: 14.1 (short formula)
## 
## 
## Danielson-Bryan
##   Parameters: default 
##          DB1: 9.86 
##          DB2: 26.39 
##        Grade: &gt;= 13 (college) 
## 
## 
## Dickes-Steiwer&#39;s Handformel
##   Parameters: default 
##          TTR: 0.53 
##        Score: 32.21 
## 
## 
## Easy Listening Formula
##   Parameters: default 
##       Exsyls: 222 
##        Score: 12.33 
## 
## 
## Farr-Jenkins-Paterson
##   Parameters: default 
##           RE: 33.19 
##        Grade: &gt;= 13 (college) 
## 
## 
## Flesch Reading Ease
##   Parameters: en (Flesch) 
##           RE: 33.98 
##        Grade: &gt;= 13 (college) 
## 
## 
## Flesch-Kincaid Grade Level
##   Parameters: default 
##        Grade: 16.19 
##          Age: 21.19 
## 
## 
## Gunning Frequency of Gobbledygook (FOG)
##   Parameters: default 
##        Grade: 18.69 
## 
## 
## FORCAST
##   Parameters: default 
##        Grade: 10.99 
##          Age: 15.99 
## 
## 
## Fucks&#39; Stilcharakteristik
##        Score: 51.67 
##        Grade: 7.19 
## 
## 
## Gutiérrez Fórmula de Comprensibilidad
##        Score: 33.48 
## 
## 
## Linsear Write
##   Parameters: default 
##   Easy words: 80.4 
##   Hard words: 19.6 
##        Grade: 21.5 
## 
## 
## Läsbarhetsindex (LIX)
##   Parameters: default 
##        Index: 65.24 
##       Rating: very difficult 
##        Grade: &gt; 11 
## 
## 
## Neue Wiener Sachtextformeln
##   Parameters: default 
##        nWS 1: 10.57 
##        nWS 2: 11.07 
##        nWS 3: 10.58 
##        nWS 4: 11.89 
## 
## 
## Readability Index (RIX)
##   Parameters: default 
##        Index: 10.61 
##        Grade: &gt; 12 (college) 
## 
## 
## Simple Measure of Gobbledygook (SMOG)
##   Parameters: default 
##        Grade: 17.19 
##          Age: 22.19 
## 
## 
## Strain Index
##   Parameters: default 
##        Index: 15.5 
## 
## 
## Tränkle-Bailer Formulas
##    Parameters: default 
##  Prepositions: 13%
##  Conjunctions: 3%
##          TB 1: 18.59 
##          TB 2: 27.15 
## 
## 
## Kuntzsch&#39;s Text-Redundanz-Index
##   Parameters: default 
##  Short words: 334 
##  Punctuation: 78 
##      Foreign: 0 
##        Score: -56.88 
## 
## 
## Tuldava&#39;s Text Difficulty Formula
##   Parameters: default 
##        Index: 5.74 
## 
## 
## Wheeler-Smith
##   Parameters: default 
##        Score: 123.33 
##        Grade: &gt; 4 
## 
## Text language: en</code></pre>
<p>To get a more condensed overview of the results try the
<code>summary()</code> method:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" tabindex="-1"></a><span class="fu">summary</span>(readbl.txt)</span></code></pre></div>
<pre><code>## Text language: en</code></pre>
<pre><code>##                    index     flavour    raw           grade  age
## 1                    ARI                              18.73     
## 2             Coleman C1                 39                     
## 3             Coleman C2                 37                     
## 4             Coleman C3                 35                     
## 5             Coleman C4                 36                     
## 6           Coleman-Liau                 33            14.1     
## 7    Danielson-Bryan DB1               9.86                     
## 8    Danielson-Bryan DB2              26.39 &gt;= 13 (college)     
## 9         Dickes-Steiwer              32.21                     
## 10                   ELF              12.33                     
## 11 Farr-Jenkins-Paterson              33.19 &gt;= 13 (college)     
## 12                Flesch en (Flesch)  33.98 &gt;= 13 (college)     
## 13        Flesch-Kincaid                              16.19 21.2
## 14                   FOG                              18.69     
## 15               FORCAST                              10.99   16
## 16                 Fucks              51.67            7.19     
## 17             Gutierrez              33.48                     
## 18         Linsear-Write                               21.5     
## 19                   LIX              65.24            &gt; 11     
## 20                  nWS1                              10.57     
## 21                  nWS2                              11.07     
## 22                  nWS3                              10.58     
## 23                  nWS4                              11.89     
## 24                   RIX              10.61  &gt; 12 (college)     
## 25                  SMOG                              17.19 22.2
## 26                Strain               15.5                     
## 27   Traenkle-Bailer TB1              18.59                     
## 28   Traenkle-Bailer TB2              27.15                     
## 29                   TRI             -56.88                     
## 30               Tuldava               5.74                     
## 31         Wheeler-Smith             123.33             &gt; 4</code></pre>
<p>The <code>summary()</code> method supports an additional flat format,
which basically turns the table into a named numeric vector, using the
raw values (because all indices have raw values, but only a few more
than that). This format comes very handy when you want to use the output
in further calculations:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" tabindex="-1"></a><span class="fu">summary</span>(readbl.txt, <span class="at">flat=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##                   ARI            Coleman.C1            Coleman.C2 
##                 18.73                 39.00                 37.00 
##            Coleman.C3            Coleman.C4          Coleman.Liau 
##                 35.00                 36.00                 33.00 
##   Danielson.Bryan.DB1   Danielson.Bryan.DB2        Dickes.Steiwer 
##                  9.86                 26.39                 32.21 
##                   ELF Farr.Jenkins.Paterson                Flesch 
##                 12.33                 33.19                 33.98 
##        Flesch.Kincaid                   FOG               FORCAST 
##                 16.19                 18.69                 10.99 
##                 Fucks             Gutierrez         Linsear.Write 
##                 51.67                 33.48                 21.50 
##                   LIX                  nWS1                  nWS2 
##                 65.24                 10.57                 11.07 
##                  nWS3                  nWS4                   RIX 
##                 10.58                 11.89                 10.61 
##                  SMOG                Strain   Traenkle.Bailer.TB1 
##                 17.19                 15.50                 18.59 
##   Traenkle.Bailer.TB2                   TRI               Tuldava 
##                 27.15                -56.88                  5.74 
##         Wheeler.Smith 
##                123.33</code></pre>
<p>If you’re interested in a particular formula, again a wrapper
function might be more convenient:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" tabindex="-1"></a>flesch.res <span class="ot">&lt;-</span> <span class="fu">flesch</span>(tagged.text, <span class="at">hyphen=</span>hyph.txt.en)</span>
<span id="cb59-2"><a href="#cb59-2" tabindex="-1"></a>lix.res <span class="ot">&lt;-</span> <span class="fu">LIX</span>(tagged.text)   <span class="co"># LIX doesn&#39;t need syllable count</span></span>
<span id="cb59-3"><a href="#cb59-3" tabindex="-1"></a>lix.res</span></code></pre></div>
<pre><code>## 
## Läsbarhetsindex (LIX)
##   Parameters: default 
##        Index: 65.24 
##       Rating: very difficult 
##        Grade: &gt; 11 
## 
## Text language: en</code></pre>
<div id="readability-from-numeric-data" class="section level3">
<h3>Readability from numeric data</h3>
<p>It is possible to calculate the readability measures from the
relevant key values directly, rather than analyze an actual text, by
using <code>readability.num()</code> instead of
<code>readability()</code>. If you need to reanalyze a particular text,
this can be considerably faster. Therefore, all objects returned by
<code>readability()</code> can directly be fed to
<code>readability.num()</code>, since all relevant data is present in
the <code>desc</code> slot.</p>
</div>
</div>
<div id="language-detection" class="section level2">
<h2>Language detection</h2>
<p>Another feature of this package is the detection of the language a
text was (most probably) written in. This is done by gzipping reference
texts in known languages, gzipping them again with addition of a small
sample of the text in unknown language, and determining the case where
the additional sample causes the smallest increase in file size <span class="citation">(as described in Benedetto, Caglioti, &amp; Loreto,
2002)</span>. By default, the compressed objects will be created in
memory only.</p>
<p>To use the function <code>guess.lang()</code>, you first need to
download the reference material. In this implementation, the Universal
Declaration of Human Rights in unicode formatting is used, because the
document holds the world record of beeing the text translated into the
most languages, and is <a href="https://www.unicode.org/udhr/">publicly
available</a>. Please get the zipped archive with all translations in
.txt format. You can, but don’t have to unzip the archive. The text to
find the language of must also be in a unicode .txt file:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" tabindex="-1"></a>guessed <span class="ot">&lt;-</span> <span class="fu">guess.lang</span>(</span>
<span id="cb61-2"><a href="#cb61-2" tabindex="-1"></a>  <span class="fu">file.path</span>(<span class="fu">find.package</span>(<span class="st">&quot;koRpus&quot;</span>),<span class="st">&quot;tests&quot;</span>,<span class="st">&quot;testthat&quot;</span>,<span class="st">&quot;sample_text.txt&quot;</span>),</span>
<span id="cb61-3"><a href="#cb61-3" tabindex="-1"></a>  <span class="at">udhr.path=</span><span class="st">&quot;~/downloads/udhr_txt.zip&quot;</span></span>
<span id="cb61-4"><a href="#cb61-4" tabindex="-1"></a>)</span>
<span id="cb61-5"><a href="#cb61-5" tabindex="-1"></a><span class="fu">summary</span>(guessed)</span></code></pre></div>
<pre><code>##   Estimated language: English
##           Identifier: eng
##               Region: Europe
## 
## 435 different languages were checked.
## 
## Distribution of compression differences:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   136.0   168.0   176.0   190.7   184.0   280.0 
## 
##   SD: 38.21 
## 
## Top 5 guesses:
##                         name iso639-3 bcp47 region diff  diff.std
## 1                    English      eng    en Europe  136 -1.430827
## 2                      Scots      sco   sco Europe  136 -1.430827
## 3           Pidgin, Nigerian      pcm   pcm Africa  144 -1.221473
## 4   Catalan-Valencian-Balear      cat    ca Europe  152 -1.012119
## 5                     French      fra    fr Europe  152 -1.012119
## 
## Last 5 guesses:
##                         name iso639-3   bcp47 region diff diff.std
## 431                  Burmese      mya      my   Asia  280 2.337547
## 432                     Shan      shn     shn   Asia  280 2.337547
## 433                    Tamil      tam      ta   Asia  280 2.337547
## 434     Vietnamese (Han nom)      vie vi-Hani   Asia  280 2.337547
## 435             Chinese, Yue      yue     yue   Asia  280 2.337547</code></pre>
</div>
<div id="using-korpus-with-other-pos-taggers" class="section level2">
<h2>Using <code>koRpus</code> with other POS taggers</h2>
<p>You might not want to use <code>TreeTagger</code> for POS tagging or
have a corpus of already tagged texts that you would like to process
with <code>koRpus</code>. For use cases like these, the package provides
a method called <code>readTagged()</code>. It is designed to import
texts that are already tokenized, lemmatized and tagged as a matrix or
data frame.</p>
<div id="example-udpipe" class="section level3">
<h3>Example: <code>udpipe</code></h3>
<p>Let’s tag an english sample text with
<code>udpipe::udpipe_annotate()</code>:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" tabindex="-1"></a><span class="fu">library</span>(udpipe)</span>
<span id="cb63-2"><a href="#cb63-2" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">udpipe_download_model</span>(<span class="at">language=</span><span class="st">&quot;english&quot;</span>)</span>
<span id="cb63-3"><a href="#cb63-3" tabindex="-1"></a>ud_en <span class="ot">&lt;-</span> <span class="fu">udpipe_load_model</span>(model<span class="sc">$</span>file_model)</span>
<span id="cb63-4"><a href="#cb63-4" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">udpipe_annotate</span>(</span>
<span id="cb63-5"><a href="#cb63-5" tabindex="-1"></a>  ud_en,</span>
<span id="cb63-6"><a href="#cb63-6" tabindex="-1"></a>  <span class="at">x=</span><span class="st">&quot;This is my sample text.&quot;</span></span>
<span id="cb63-7"><a href="#cb63-7" tabindex="-1"></a>)</span></code></pre></div>
<p>In order to use the annotated object <code>x</code> with
<code>koRpus</code>, we can then convert it into a <code>kRp.text</code>
class object:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" tabindex="-1"></a>x_kRp <span class="ot">&lt;-</span> <span class="fu">readTagged</span>(</span>
<span id="cb64-2"><a href="#cb64-2" tabindex="-1"></a>  <span class="fu">as.data.frame</span>(x),</span>
<span id="cb64-3"><a href="#cb64-3" tabindex="-1"></a>  <span class="at">lang=</span><span class="st">&quot;en&quot;</span>,</span>
<span id="cb64-4"><a href="#cb64-4" tabindex="-1"></a>  <span class="at">tagger=</span><span class="st">&quot;manual&quot;</span>,</span>
<span id="cb64-5"><a href="#cb64-5" tabindex="-1"></a>  <span class="at">doc_id=</span><span class="fu">as.data.frame</span>(x)[<span class="dv">1</span>,<span class="st">&quot;doc_id&quot;</span>],</span>
<span id="cb64-6"><a href="#cb64-6" tabindex="-1"></a>  <span class="at">mtx_cols=</span><span class="fu">c</span>(</span>
<span id="cb64-7"><a href="#cb64-7" tabindex="-1"></a>    <span class="at">token=</span><span class="st">&quot;token&quot;</span>,</span>
<span id="cb64-8"><a href="#cb64-8" tabindex="-1"></a>    <span class="at">tag=</span><span class="st">&quot;xpos&quot;</span>,</span>
<span id="cb64-9"><a href="#cb64-9" tabindex="-1"></a>    <span class="at">lemma=</span><span class="st">&quot;lemma&quot;</span></span>
<span id="cb64-10"><a href="#cb64-10" tabindex="-1"></a>  )</span>
<span id="cb64-11"><a href="#cb64-11" tabindex="-1"></a>)</span></code></pre></div>
<p>The resulting object <code>x_kRp</code> can now be used just as if
the sample text had been tagged using <code>treetag()</code>:</p>
<pre><code>###   doc_id  token  tag  lemma lttr     wclass desc stop stem idx sntc
### 1   doc1   This   DT   this    4 determiner   NA   NA   NA   1    1
### 2   doc1     is  VBZ     be    2       verb   NA   NA   NA   2    1
### 3   doc1     my PRP$     my    2    pronoun   NA   NA   NA   3    1
### 4   doc1 sample   NN sample    6       noun   NA   NA   NA   4    1
### 5   doc1   text   NN   text    4       noun   NA   NA   NA   5    1
### 6   doc1      . SENT      .    1   fullstop   NA   NA   NA   6    1
</code></pre>
<p>This import method should basically work for any third party POS
tagging, as long as the tagset is compatible with the ones provided by
the <code>koRpus.lang.*</code> packages. In this case, this is true for
the English model imported via <code>udpipe_load_model</code>.</p>
<p>Since <code>udpipe_annotate</code> does additionally use the
Universal Tagset and <code>koRpus</code> supports that as well, you can
use it as a less precise fallback when the language specific tagset
turns out to be incompatible. For this you simply have to use a
different column for <code>tag</code>:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" tabindex="-1"></a>x_kRp <span class="ot">&lt;-</span> <span class="fu">readTagged</span>(</span>
<span id="cb66-2"><a href="#cb66-2" tabindex="-1"></a>  <span class="fu">as.data.frame</span>(x),</span>
<span id="cb66-3"><a href="#cb66-3" tabindex="-1"></a>  <span class="at">lang=</span><span class="st">&quot;en&quot;</span>,</span>
<span id="cb66-4"><a href="#cb66-4" tabindex="-1"></a>  <span class="at">tagger=</span><span class="st">&quot;manual&quot;</span>,</span>
<span id="cb66-5"><a href="#cb66-5" tabindex="-1"></a>  <span class="at">doc_id=</span><span class="fu">as.data.frame</span>(x)[<span class="dv">1</span>,<span class="st">&quot;doc_id&quot;</span>],</span>
<span id="cb66-6"><a href="#cb66-6" tabindex="-1"></a>  <span class="at">mtx_cols=</span><span class="fu">c</span>(</span>
<span id="cb66-7"><a href="#cb66-7" tabindex="-1"></a>    <span class="at">token=</span><span class="st">&quot;token&quot;</span>,</span>
<span id="cb66-8"><a href="#cb66-8" tabindex="-1"></a>    <span class="at">tag=</span><span class="st">&quot;upos&quot;</span>,</span>
<span id="cb66-9"><a href="#cb66-9" tabindex="-1"></a>    <span class="at">lemma=</span><span class="st">&quot;lemma&quot;</span></span>
<span id="cb66-10"><a href="#cb66-10" tabindex="-1"></a>  )</span>
<span id="cb66-11"><a href="#cb66-11" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>###   doc_id  token  tag  lemma lttr    wclass desc stop stem idx sntc
### 1   doc1   This PRON   this    4   pronoun   NA   NA   NA   1    1
### 2   doc1     is  AUX     be    2 auxiliary   NA   NA   NA   2    1
### 3   doc1     my PRON     my    2   pronoun   NA   NA   NA   3    1
### 4   doc1 sample NOUN sample    6      noun   NA   NA   NA   4    1
### 5   doc1   text NOUN   text    4      noun   NA   NA   NA   5    1
### 6   doc1      . SENT      .    1  fullstop   NA   NA   NA   6    1</code></pre>
</div>
</div>
</div>
<div id="extending-korpus" class="section level1">
<h1>Extending <code>koRpus</code></h1>
<p>The language support of this package has a modular design. There are
some pre-built language packages in <a href="https://undocumeantit.github.io/repos/">the <code>l10n</code>
repository</a>, and with a little effort you should be able to add new
languages yourself. You need the package sources for this, then
basically you will have to add a new file to it and rebuild/reinstall
the package. More details on this topic can be found in
<code>inst/README.languages</code>. Once you got a new language to work
with <code>koRpus</code>, I’d be happy to include your module in the
official distribution.</p>
</div>
<div id="analyzing-full-corpora" class="section level1">
<h1>Analyzing full corpora</h1>
<p>Despite its name, the scope of <code>koRpus</code> is single texts.
If you would like to do analysis an a full corpus of texts, have a look
at the <a href="https://github.com/unDocUMeantIt/tm.plugin.koRpus">plugin package
<code>tm.plugin.koRpus</code></a>.</p>
</div>
<div id="acknowledgements" class="section level1">
<h1>Acknowledgements</h1>
<p>The APA style used in this vignette was kindly provided by the <a href="https://citationstyles.org">CSL project</a>, licensed under <a href="https://creativecommons.org/licenses/by-sa/3.0/">Creative Commons
Attribution-ShareAlike 3.0 Unported license</a>.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-benedetto_gzip_2002" class="csl-entry">
Benedetto, D., Caglioti, E., &amp; Loreto, V. (2002). Language trees and
zipping. <em>Physical Review Letters</em>, <em>88</em>(4), 048702.
</div>
<div id="ref-bormuth_cloze_1968" class="csl-entry">
Bormuth, J. R. (1968). Cloze test readability: Criterion reference
scores. <em>Journal of Educational Measurement</em>, <em>5</em>(3),
189–196.
</div>
<div id="ref-dale_formula_1948" class="csl-entry">
Dale, E., &amp; Chall, J. S. (1948). A formula for predicting
readability. <em>Educational Research Bulletin</em>, 11–28.
</div>
<div id="ref-liang_word_1983" class="csl-entry">
Liang, F. M. (1983). <em>Word hy-phen-a-tion by com-put-er</em> (PhD
thesis). Stanford University, Dept. Computer Science, Stanford.
</div>
<div id="ref-maas_ueber_1972" class="csl-entry">
Maas, H. D. (1972). Über den <span class="nocase"><span>Z</span>usammenhang</span> zwischen <span class="nocase"><span>W</span>ortschatzumfang</span> und <span class="nocase"><span>L</span>änge</span> eines <span class="nocase"><span>T</span>extes</span>. <em>Zeitschrift Für
Literaturwissenschaft Und Linguistik</em>, <em>2</em>(8), 73–79.
</div>
<div id="ref-mccarthy_vocd_2007" class="csl-entry">
McCarthy, P. M., &amp; Jarvis, S. (2007). Vocd – a theoretical and
empirical evaluation. <em>Language Testing</em>, <em>24</em>(4),
459–488.
</div>
<div id="ref-mccarthy_mtld_2010" class="csl-entry">
McCarthy, P. M., &amp; Jarvis, S. (2010). <span>MTLD,</span> <span class="nocase">vocd-D,</span> and <span>HD-D:</span> A validation study
of sophisticated approaches to lexical diversity assessment.
<em>Behavior Research Methods</em>, <em>42</em>(2), 381–392.
</div>
<div id="ref-quasthoff_LCC_2006" class="csl-entry">
Quasthoff, U., Richter, M., &amp; Biemann, C. (2006). Corpus portal for
search in monolingual corpora. In <em>Proceedings of the fifth
international conference on language resources and evaluation</em> (pp.
1799–1802). Genoa.
</div>
<div id="ref-schmid_TT_1994" class="csl-entry">
Schmid, H. (1994). Probabilistic part-of-speec tagging using decision
trees. In <em>International conference on new methods in language
processing</em> (pp. 44–49). Manchester, UK.
</div>
<div id="ref-spache_new_1953" class="csl-entry">
Spache, G. (1953). A new readability formula for primary-grade reading
materials. <em>The Elementary School Journal</em>, <em>53</em>(7),
410–413.
</div>
<div id="ref-tweedie_how_1998" class="csl-entry">
Tweedie, F. J., &amp; Baayen, R. H. (1998). How variable may a constant
be? Measures of lexical richness in perspective. <em>Computers and the
Humanities</em>, <em>32</em>(5), 323–352.
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>For a free implementation try <a href="https://strawberryperl.com" class="uri">https://strawberryperl.com</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Like <a href="https://7-zip.org" class="uri">https://7-zip.org</a><a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Unfortunately, these language packages did not get the
approval of the CRAN maintainers and are officially hosted at (<a href="https://undocumeantit.github.io/repos/l10n/" class="uri">https://undocumeantit.github.io/repos/l10n/</a>)[<a href="https://undocumeantit.github.io/repos/l10n/" class="uri">https://undocumeantit.github.io/repos/l10n/</a>]. For your
convenience the function <code>install.koRpus.lang()</code> can be used
to easily install them anyway.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Presets are defined in the language support packages,
usually named like their respective two-character language identifier.
Refer to their documentation.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>For informtaion on the measures shown see <span class="citation">Tweedie &amp; Baayen (1998)</span>, <span class="citation">McCarthy &amp; Jarvis (2007)</span>, <span class="citation">McCarthy &amp; Jarvis (2010)</span>.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Characteristics can be looked at to examine each
measure’s dependency on text length. They are calculated by computing
each measure repeatedly, beginning with only the first token, then
adding the next, progressing until the full text was analyzed.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>The package also has a function called
<code>read.corp.custom()</code> which can be used to process language
corpora yourself, and store the results in an object of class
<code>kRp.corp.freq</code>, which is the class returned by
<code>read.corp.LCC()</code> and <code>read.corp.celex()</code> as well.
That is, if you can’t get any already analyzed corpus database but have
a huge language corpus at hand, you can create your own frequency
database. But be warned that depending on corpus size and your hardware,
this might take ages. On the other hand, <code>read.corp.custom()</code>
will provide inverse document frequency (idf) values for all types,
which is necessary to compute tf-idf with <code>freq.analysis()</code><a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Actually, it unterstands two different LCC formats, both
the older .zip and the newer .tar archive format.<a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>This can easily be done by calling
<code>as(freq.analysis.res, &quot;kRp.text&quot;)</code>.<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>This sorting depends on proper POS-tagging, so this
will only contain useful data if you used <code>treetag()</code> instead
of <code>tokenize()</code>.<a href="#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>And can then be corrected by using the function
<code>correct.tag()</code><a href="#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>Whether this is the case can be looked up in the
documentation.<a href="#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>The <code>hyphen()</code> method was originally
implemented as part of the <code>koRpus</code> package, but was later
split off into its own package called <code>sylly</code>.<a href="#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>For example, this can be comfortably done with RKWard:
<a href="https://rkward.kde.org" class="uri">https://rkward.kde.org</a><a href="#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>Please note that as of version 0.04-18, the correctness
of some of these calculations has not been extensively validated yet.
The package was released nonetheless, also to find outstanding bugs in
the implemented measures. Any information on the validity of its results
is very welcome!<a href="#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>Measures which rely on word lists will be skipped if no
list is provided.<a href="#fnref16" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
